# BCI Transfer Learning & HER2 Classification Pipeline

–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è BCI —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π **Transfer Learning** –∏ **HER2 –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏**.

## üìã –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–û–±–∑–æ—Ä](#–æ–±–∑–æ—Ä)
2. [–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞](#—Å—Ç—Ä—É–∫—Ç—É—Ä–∞-–ø—Ä–æ–µ–∫—Ç–∞)
3. [–£—Å—Ç–∞–Ω–æ–≤–∫–∞](#—É—Å—Ç–∞–Ω–æ–≤–∫–∞)
4. [–ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç](#–±—ã—Å—Ç—Ä—ã–π-—Å—Ç–∞—Ä—Ç)
5. [–î–µ—Ç–∞–ª—å–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ](#–¥–µ—Ç–∞–ª—å–Ω–æ–µ-—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ)
6. [–†–µ–∑—É–ª—å—Ç–∞—Ç—ã](#—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)
7. [–î–ª—è —Å—Ç–∞—Ç—å–∏](#–¥–ª—è-—Å—Ç–∞—Ç—å–∏)

---

## üéØ –û–±–∑–æ—Ä

### –ó–∞–¥–∞—á–∏:
1. **Transfer Learning Pipeline** –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –º–∞–ª—ã—Ö –¥–∞–Ω–Ω—ã—Ö (10-50% –æ—Ç –ø–æ–ª–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞)
2. **HER2 Classification** - –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –º–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã—Ö –ø–æ–¥—Ç–∏–ø–æ–≤ (0, 1+, 2+, 3+)

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    TRANSFER LEARNING PIPELINE               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Phase 1: Pre-training (Full Dataset: 3,896 pairs)
H&E Image ‚Üí [PyramidPix2pix Generator] ‚Üí IHC Image
                    ‚Üì
           [PatchGAN Discriminator]
           Loss: L1 + L2 + L3 + L4 (Pyramid) + GAN

Phase 2: Fine-tuning (Small Dataset: 10-50%)
Pre-trained Generator ‚Üí [Fine-tune] ‚Üí Adapted Generator
                    ‚Üì
           [Strong Augmentation]
           - Color Jitter
           - Affine Transform
           - Gaussian Noise

Phase 3: Classification (Optional)
[Generator Encoder] ‚Üí [Classification Head] ‚Üí HER2 Class
                              ‚Üì
                    [0, 1+, 2+, 3+]
```

---

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
BCI-main/
‚îú‚îÄ‚îÄ BCI_dataset/                    # –ü–æ–ª–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
‚îÇ   ‚îú‚îÄ‚îÄ HE/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train/                  # 3,896 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π H&E
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test/                   # 977 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π H&E
‚îÇ   ‚îî‚îÄ‚îÄ IHC/
‚îÇ       ‚îú‚îÄ‚îÄ train/                  # 3,896 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π IHC
‚îÇ       ‚îî‚îÄ‚îÄ test/                   # 977 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π IHC
‚îÇ
‚îú‚îÄ‚îÄ BCI_dataset_small_10pct/        # 10% –æ—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞ (—Å–æ–∑–¥–∞–µ—Ç—Å—è —Å–∫—Ä–∏–ø—Ç–æ–º)
‚îú‚îÄ‚îÄ BCI_dataset_small_20pct/        # 20% –æ—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞
‚îú‚îÄ‚îÄ BCI_dataset_small_50pct/        # 50% –æ—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞
‚îÇ
‚îú‚îÄ‚îÄ PyramidPix2pix/                 # –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–¥ –º–æ–¥–µ–ª–∏
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ aligned_dataset.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ her2_aligned_dataset.py # [NEW] Dataset —Å HER2 –º–µ—Ç–∫–∞–º–∏
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pix2pix_model.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pix2pix_transfer_model.py # [NEW] Transfer + Classification
‚îÇ   ‚îú‚îÄ‚îÄ options/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train_options.py        # [MODIFIED] –ù–æ–≤—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ util/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ her2_utils.py           # [NEW] –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è HER2
‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îî‚îÄ‚îÄ test.py
‚îÇ
‚îú‚îÄ‚îÄ scripts/                        # [NEW] –°–∫—Ä–∏–ø—Ç—ã –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ create_small_dataset.py     # –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤
‚îÇ   ‚îî‚îÄ‚îÄ run_experiments.py          # –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                      # [NEW] Jupyter –Ω–æ—É—Ç–±—É–∫–∏
‚îÇ   ‚îú‚îÄ‚îÄ analysis.ipynb              # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
‚îÇ   ‚îî‚îÄ‚îÄ figures/                    # –ì—Ä–∞—Ñ–∏–∫–∏ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
‚îÇ
‚îú‚îÄ‚îÄ experiments/                    # [NEW] –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ checkpoints/                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
‚îÇ   ‚îú‚îÄ‚îÄ results/                    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
‚îÇ   ‚îî‚îÄ‚îÄ logs/                       # –õ–æ–≥–∏ –æ–±—É—á–µ–Ω–∏—è
‚îÇ
‚îî‚îÄ‚îÄ TRANSFER_LEARNING_README.md     # –≠—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
```

---

## üîß –£—Å—Ç–∞–Ω–æ–≤–∫–∞

### 1. –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è
- Python 3.8+
- PyTorch 1.9+
- CUDA 11.0+ (–¥–ª—è GPU)
- ~12GB VRAM (–¥–ª—è RTX 3060)

### 2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
cd BCI-main/PyramidPix2pix
pip install -r requirements.txt

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
pip install scikit-image scikit-learn seaborn jupyter
```

### 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU

```python
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"GPU: {torch.cuda.get_device_name(0)}")
```

---

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –í–∞—Ä–∏–∞–Ω—Ç 1: –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

```bash
cd BCI-main
python scripts/run_experiments.py --experiment all --gpu_ids 0
```

–≠—Ç–æ –≤—ã–ø–æ–ª–Ω–∏—Ç:
1. –°–æ–∑–¥–∞–Ω–∏–µ –º–∞–ª—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ (10%, 20%, 50%)
2. Pre-training –Ω–∞ –ø–æ–ª–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ
3. Fine-tuning –Ω–∞ –º–∞–ª—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö
4. –û–±—É—á–µ–Ω–∏–µ —Å HER2 –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–º
5. –û—Ü–µ–Ω–∫—É –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π

### –í–∞—Ä–∏–∞–Ω—Ç 2: –ü–æ—à–∞–≥–æ–≤—ã–π –∑–∞–ø—É—Å–∫

```bash
# –®–∞–≥ 1: –°–æ–∑–¥–∞—Ç—å –º–∞–ª—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã
python scripts/create_small_dataset.py --all

# –®–∞–≥ 2: Pre-training (–ø–æ–ª–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç)
python scripts/run_experiments.py --experiment pretrain

# –®–∞–≥ 3: Fine-tuning (10% –¥–∞–Ω–Ω—ã—Ö)
python scripts/run_experiments.py --experiment finetune --ratio 0.1

# –®–∞–≥ 4: –û–±—É—á–µ–Ω–∏–µ —Å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–º
python scripts/run_experiments.py --experiment classify
```

---

## üìñ –î–µ—Ç–∞–ª—å–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ

### 1. –°–æ–∑–¥–∞–Ω–∏–µ –º–∞–ª—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤

```bash
# –°–æ–∑–¥–∞—Ç—å 10% –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ
python scripts/create_small_dataset.py \
    --source ./BCI_dataset \
    --target ./BCI_dataset_small_10pct \
    --ratio 0.1 \
    --seed 42

# –ò–ª–∏ —Å–æ–∑–¥–∞—Ç—å –≤—Å–µ —Å—Ä–∞–∑—É
python scripts/create_small_dataset.py --all
```

**–í–∞–∂–Ω–æ**: –°–∫—Ä–∏–ø—Ç —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ HER2 —Å—Ç–∞—Ç—É—Å–æ–≤ (stratified sampling).

### 2. Pre-training –Ω–∞ –ø–æ–ª–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ

```bash
cd PyramidPix2pix

python train.py \
    --dataroot ../datasets/BCI \
    --name bci_pretrain_full \
    --gpu_ids 0 \
    --pattern L1_L2_L3_L4 \
    --batch_size 2 \
    --crop_size 512 \
    --preprocess crop \
    --n_epochs 50 \
    --n_epochs_decay 50 \
    --save_epoch_freq 10
```

### 3. Fine-tuning —Å Transfer Learning

```bash
python train.py \
    --dataroot ../datasets/BCI_small_10pct \
    --name bci_finetune_10pct \
    --gpu_ids 0 \
    --pattern L1_L2_L3_L4 \
    --pretrained_path ../experiments/checkpoints/bci_pretrain_full/latest_net_G.pth \
    --strong_augment \
    --finetune_lr_factor 0.1 \
    --batch_size 4 \
    --n_epochs 30 \
    --n_epochs_decay 20
```

**–ù–æ–≤—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `--pretrained_path`: –ø—É—Ç—å –∫ pre-trained –º–æ–¥–µ–ª–∏
- `--freeze_encoder`: –∑–∞–º–æ—Ä–æ–∑–∏—Ç—å encoder (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
- `--strong_augment`: —É—Å–∏–ª–µ–Ω–Ω—ã–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
- `--finetune_lr_factor`: –º–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è LR (0.1 = –≤ 10 —Ä–∞–∑ –º–µ–Ω—å—à–µ)

### 4. –û–±—É—á–µ–Ω–∏–µ —Å HER2 –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π

```bash
python train.py \
    --dataroot ../datasets/BCI \
    --name bci_with_classifier \
    --model pix2pix_transfer \
    --dataset_mode her2_aligned \
    --gpu_ids 0 \
    --pattern L1_L2_L3_L4 \
    --enable_classification \
    --lambda_classifier 0.5 \
    --num_classes 4 \
    --n_epochs 50 \
    --n_epochs_decay 50
```

**–ù–æ–≤—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `--enable_classification`: –≤–∫–ª—é—á–∏—Ç—å HER2 –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
- `--lambda_classifier`: –≤–µ—Å classification loss
- `--num_classes`: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤ (4 –¥–ª—è HER2)
- `--class_weighted_loss`: –≤–∑–≤–µ—à–µ–Ω–Ω—ã–π loss –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

### 5. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```bash
python test.py \
    --dataroot ../datasets/BCI \
    --name bci_pretrain_full \
    --gpu_ids 0 \
    --preprocess none
```

### 6. –û—Ü–µ–Ω–∫–∞ –º–µ—Ç—Ä–∏–∫

```bash
python evaluate.py --result_path ./results/bci_pretrain_full
```

---

## üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

### –û–∂–∏–¥–∞–µ–º—ã–µ –º–µ—Ç—Ä–∏–∫–∏

| Method | Data | PSNR ‚Üë | SSIM ‚Üë | Training Time |
|--------|------|--------|--------|---------------|
| Baseline (Full) | 3,896 | 21.16 | 0.477 | ~12h |
| Transfer 50% | 1,948 | ~20.5 | ~0.46 | ~6h |
| Transfer 20% | 780 | ~19.5 | ~0.43 | ~2.5h |
| Transfer 10% | 390 | ~18.0 | ~0.38 | ~1h |
| No Transfer 10% | 390 | ~15.5 | ~0.30 | ~1h |

### HER2 Classification

| Method | Accuracy | Notes |
|--------|----------|-------|
| Multi-task (Full) | ~65-75% | Generation + Classification |
| ResNet-18 (Real IHC) | ~70-80% | Baseline on real images |

---

## üìù –î–ª—è —Å—Ç–∞—Ç—å–∏

### Jupyter Notebook

–û—Ç–∫—Ä–æ–π—Ç–µ `notebooks/analysis.ipynb` –¥–ª—è:
- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
- –†–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫ (PSNR, SSIM)
- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏—è confusion matrix
- –ì–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–∞–±–ª–∏—Ü –≤ LaTeX

### Methods Section Draft

–°–º. —Ñ–∞–π–ª `notebooks/methods_draft.md` —Å —á–µ—Ä–Ω–æ–≤–∏–∫–æ–º —Ä–∞–∑–¥–µ–ª–∞ Methods.

### –ü—Ä–∏–º–µ—Ä—ã –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏

–ü–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –≥—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤:
- `notebooks/figures/dataset_distribution.png`
- `notebooks/figures/confusion_matrix.png`
- `notebooks/figures/visualization_*.png`

---

## üî¨ –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
- **ResNet-9blocks** (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
- Input: 3 –∫–∞–Ω–∞–ª–∞ (RGB)
- Output: 3 –∫–∞–Ω–∞–ª–∞ (RGB)
- 9 ResNet –±–ª–æ–∫–æ–≤ –≤ bottleneck

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
```python
HER2ClassificationHead(
    input_channels=256,
    num_classes=4,
    dropout=0.5
)
# Structure: AdaptiveAvgPool ‚Üí 256 ‚Üí 512 ‚Üí 256 ‚Üí 4
```

### –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –º–∞–ª—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- Color Jitter: brightness=0.3, contrast=0.3, saturation=0.2
- Affine: rotation=¬±10¬∞, translate=¬±5%, scale=0.9-1.1
- Gaussian Blur: kernel=3-5, sigma=0.1-2.0
- Gaussian Noise: std=0.01-0.05

---

## ‚ùì FAQ

**Q: –°–∫–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–Ω–∏–º–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ?**
- Full dataset (100 epochs): ~12-15 —á–∞—Å–æ–≤ –Ω–∞ RTX 3060
- Small dataset (50 epochs): ~1-3 —á–∞—Å–∞

**Q: –ú–æ–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å CPU?**
- –î–∞, –Ω–æ –æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ. –î–æ–±–∞–≤—å—Ç–µ `--gpu_ids -1`

**Q: –ö–∞–∫ —É–º–µ–Ω—å—à–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏?**
- –£–º–µ–Ω—å—à–∏—Ç–µ `--batch_size` –¥–æ 1
- –£–º–µ–Ω—å—à–∏—Ç–µ `--crop_size` –¥–æ 256

**Q: –ö–∞–∫ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –ø—Ä–µ—Ä–≤–∞–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ?**
```bash
python train.py ... --continue_train --epoch latest
```

---

## üìö –¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```bibtex
@InProceedings{Liu_2022_CVPR,
    author    = {Liu, Shengjie and Zhu, Chuang and Xu, Feng and Jia, Xinyu and Shi, Zhongyue and Jin, Mulan},
    title     = {BCI: Breast Cancer Immunohistochemical Image Generation Through Pyramid Pix2pix},
    booktitle = {CVPR Workshops},
    year      = {2022},
    pages     = {1815-1824}
}
```

---

## üìß –ö–æ–Ω—Ç–∞–∫—Ç—ã

–ü—Ä–∏ –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤ –æ–±—Ä–∞—â–∞–π—Ç–µ—Å—å –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º –∞–≤—Ç–æ—Ä–∞–º BCI:
- Shengjie Liu (shengjie.Liu@bupt.edu.cn)
- Chuang Zhu (czhu@bupt.edu.cn)


